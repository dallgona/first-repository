{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07a30e58",
   "metadata": {},
   "source": [
    "# 미니 프로젝트 : 가위바위보 분류기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2b896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fbb893",
   "metadata": {},
   "source": [
    "데이터 불러오기 + Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21c6f6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec08257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419  images to be resized.\n",
      "419  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "975ab7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398  images to be resized.\n",
      "398  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들이기\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ccaceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398  images to be resized.\n",
      "398  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들이기\n",
    "\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a84e6239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1215 입니다.\n",
      "x_train shape: (1215, 28, 28, 3)\n",
      "y_train shape: (1215,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=1215):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a43031",
   "metadata": {},
   "source": [
    "이미지 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15370dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bbe225",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88ccf7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 23,747\n",
      "Trainable params: 23,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "n_channel_1 = 32\n",
    "n_channel_2 = 64\n",
    "n_dense = 64\n",
    "n_train_epoch = 20\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "# 입력 크기와 레이어 수 조정\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "# 과적합 방지: 드롭아웃 추가\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "\n",
    "# 특성 벡터화 및 Fully Connected 레이어\n",
    "model.add(keras.layers.GlobalAveragePooling2D())  # 더 효율적인 풀링\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "\n",
    "# 출력 레이어: 가위, 바위, 보의 3개 클래스\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "# 모델 구조 출력\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f913ee",
   "metadata": {},
   "source": [
    "딥러닝 네트워크 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f681c5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='conv2d_6_input'), name='conv2d_6_input', description=\"created by layer 'conv2d_6_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='conv2d_6_input'), name='conv2d_6_input', description=\"created by layer 'conv2d_6_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "469/469 [==============================] - ETA: 0s - loss: 0.8112 - accuracy: 0.6429WARNING:tensorflow:Model was constructed with shape (None, 28, 28, 3) for input KerasTensor(type_spec=TensorSpec(shape=(None, 28, 28, 3), dtype=tf.float32, name='conv2d_6_input'), name='conv2d_6_input', description=\"created by layer 'conv2d_6_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "469/469 [==============================] - 28s 56ms/step - loss: 0.8112 - accuracy: 0.6429 - val_loss: 0.6314 - val_accuracy: 0.7390\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.6385 - accuracy: 0.7333 - val_loss: 0.6125 - val_accuracy: 0.7413\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.5769 - accuracy: 0.7626 - val_loss: 0.5161 - val_accuracy: 0.7907\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.5328 - accuracy: 0.7841 - val_loss: 0.5083 - val_accuracy: 0.7927\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 26s 56ms/step - loss: 0.5108 - accuracy: 0.7951 - val_loss: 0.4695 - val_accuracy: 0.8093\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.4919 - accuracy: 0.7996 - val_loss: 0.4450 - val_accuracy: 0.8253\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.4751 - accuracy: 0.8082 - val_loss: 0.4409 - val_accuracy: 0.8260\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 26s 55ms/step - loss: 0.4562 - accuracy: 0.8201 - val_loss: 0.4613 - val_accuracy: 0.8200\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 26s 54ms/step - loss: 0.4452 - accuracy: 0.8252 - val_loss: 0.4259 - val_accuracy: 0.8260\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.4354 - accuracy: 0.8275 - val_loss: 0.4221 - val_accuracy: 0.8310\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.4219 - accuracy: 0.8355 - val_loss: 0.3983 - val_accuracy: 0.8407\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 26s 54ms/step - loss: 0.4113 - accuracy: 0.8385 - val_loss: 0.3823 - val_accuracy: 0.8500\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.4010 - accuracy: 0.8443 - val_loss: 0.3727 - val_accuracy: 0.8500\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3919 - accuracy: 0.8489 - val_loss: 0.3653 - val_accuracy: 0.8583\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3849 - accuracy: 0.8490 - val_loss: 0.3557 - val_accuracy: 0.8647\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3758 - accuracy: 0.8541 - val_loss: 0.3483 - val_accuracy: 0.8603\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3692 - accuracy: 0.8565 - val_loss: 0.3656 - val_accuracy: 0.8613\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3578 - accuracy: 0.8619 - val_loss: 0.3522 - val_accuracy: 0.8620\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3503 - accuracy: 0.8653 - val_loss: 0.3436 - val_accuracy: 0.8637\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 25s 54ms/step - loss: 0.3485 - accuracy: 0.8659 - val_loss: 0.3696 - val_accuracy: 0.8597\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요. \n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# 🧹 CIFAR-10 데이터 로드 및 필터링 (0, 1, 2 클래스만)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "mask_train = np.isin(y_train, [0, 1, 2])  # 0, 1, 2 클래스만 선택\n",
    "x_train = x_train[mask_train.flatten()]  # 0, 1, 2에 해당하는 데이터만 선택\n",
    "y_train = y_train[mask_train.flatten()]\n",
    "\n",
    "mask_test = np.isin(y_test, [0, 1, 2])  # 0, 1, 2 클래스만 선택\n",
    "x_test = x_test[mask_test.flatten()]  # 0, 1, 2에 해당하는 데이터만 선택\n",
    "y_test = y_test[mask_test.flatten()]\n",
    "\n",
    "# 🧹 **데이터 정규화**\n",
    "x_train = x_train.astype('float32') / 255.0  # 0~1로 스케일링\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# 🛠️ **모델 설계**\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.GlobalAveragePooling2D())\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))  # 가위, 바위, 보의 3개 클래스\n",
    "\n",
    "# ⚙️ **모델 컴파일**\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 🚀 **모델 훈련**\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=20, \n",
    "    batch_size=32, \n",
    "    validation_data=(x_test, y_test), \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fc749e",
   "metadata": {},
   "source": [
    "test accuracy 측정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "effad4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 '/aiffel/aiffel/rock_scissor_paper/test/scissor' 경로에 있는 이미지를 리사이즈합니다.\n",
      "총 이미지 파일 개수: 101개\n",
      "0/101 이미지 리사이즈 완료\n",
      "10/101 이미지 리사이즈 완료\n",
      "20/101 이미지 리사이즈 완료\n",
      "30/101 이미지 리사이즈 완료\n",
      "40/101 이미지 리사이즈 완료\n",
      "50/101 이미지 리사이즈 완료\n",
      "60/101 이미지 리사이즈 완료\n",
      "70/101 이미지 리사이즈 완료\n",
      "80/101 이미지 리사이즈 완료\n",
      "❌ 오류 발생: /aiffel/aiffel/rock_scissor_paper/test/scissor/scissor.zip - cannot identify image file '/aiffel/aiffel/rock_scissor_paper/test/scissor/scissor.zip'\n",
      "100/101 이미지 리사이즈 완료\n",
      "🎉 모든 이미지 리사이즈 완료 - 총 101개 파일 리사이즈됨.\n",
      "📁 '/aiffel/aiffel/rock_scissor_paper/test/rock' 경로에 있는 이미지를 리사이즈합니다.\n",
      "총 이미지 파일 개수: 101개\n",
      "0/101 이미지 리사이즈 완료\n",
      "10/101 이미지 리사이즈 완료\n",
      "20/101 이미지 리사이즈 완료\n",
      "❌ 오류 발생: /aiffel/aiffel/rock_scissor_paper/test/rock/rock.zip - cannot identify image file '/aiffel/aiffel/rock_scissor_paper/test/rock/rock.zip'\n",
      "30/101 이미지 리사이즈 완료\n",
      "40/101 이미지 리사이즈 완료\n",
      "50/101 이미지 리사이즈 완료\n",
      "60/101 이미지 리사이즈 완료\n",
      "70/101 이미지 리사이즈 완료\n",
      "80/101 이미지 리사이즈 완료\n",
      "90/101 이미지 리사이즈 완료\n",
      "100/101 이미지 리사이즈 완료\n",
      "🎉 모든 이미지 리사이즈 완료 - 총 101개 파일 리사이즈됨.\n",
      "📁 '/aiffel/aiffel/rock_scissor_paper/test/paper' 경로에 있는 이미지를 리사이즈합니다.\n",
      "총 이미지 파일 개수: 101개\n",
      "0/101 이미지 리사이즈 완료\n",
      "10/101 이미지 리사이즈 완료\n",
      "20/101 이미지 리사이즈 완료\n",
      "30/101 이미지 리사이즈 완료\n",
      "❌ 오류 발생: /aiffel/aiffel/rock_scissor_paper/test/paper/paper.zip - cannot identify image file '/aiffel/aiffel/rock_scissor_paper/test/paper/paper.zip'\n",
      "40/101 이미지 리사이즈 완료\n",
      "50/101 이미지 리사이즈 완료\n",
      "60/101 이미지 리사이즈 완료\n",
      "70/101 이미지 리사이즈 완료\n",
      "80/101 이미지 리사이즈 완료\n",
      "90/101 이미지 리사이즈 완료\n",
      "100/101 이미지 리사이즈 완료\n",
      "🎉 모든 이미지 리사이즈 완료 - 총 101개 파일 리사이즈됨.\n",
      "📥 데이터 로드 중... 경로: /aiffel/aiffel/rock_scissor_paper/test\n",
      "📁 'scissor' 라벨의 이미지 개수: 101개\n",
      "❌ 오류 발생: /aiffel/aiffel/rock_scissor_paper/test/scissor/scissor.zip - cannot identify image file '/aiffel/aiffel/rock_scissor_paper/test/scissor/scissor.zip'\n",
      "📁 'rock' 라벨의 이미지 개수: 101개\n",
      "❌ 오류 발생: /aiffel/aiffel/rock_scissor_paper/test/rock/rock.zip - cannot identify image file '/aiffel/aiffel/rock_scissor_paper/test/rock/rock.zip'\n",
      "📁 'paper' 라벨의 이미지 개수: 101개\n",
      "❌ 오류 발생: /aiffel/aiffel/rock_scissor_paper/test/paper/paper.zip - cannot identify image file '/aiffel/aiffel/rock_scissor_paper/test/paper/paper.zip'\n",
      "📏 데이터 로드 완료: x_data.shape=(300, 28, 28, 3), y_data.shape=(300,)\n",
      "📏 x_test shape: (300, 28, 28, 3), y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image  # 이미지 파일을 불러오기 위해 PIL(Pillow) 라이브러리 사용\n",
    "\n",
    "# 🧱 **1. 이미지 크기 조정 함수 (resize_images)**\n",
    "def resize_images(image_dir_path, target_size=(28, 28)):  # 이미지를 (28, 28)로 리사이즈\n",
    "    print(f\"📁 '{image_dir_path}' 경로에 있는 이미지를 리사이즈합니다.\")\n",
    "    image_files = os.listdir(image_dir_path)  # 폴더에 있는 이미지 파일 목록\n",
    "    total_files = len(image_files)\n",
    "    print(f\"총 이미지 파일 개수: {total_files}개\")\n",
    "    \n",
    "    for i, file_name in enumerate(image_files):\n",
    "        file_path = os.path.join(image_dir_path, file_name)  # 이미지 파일의 전체 경로\n",
    "        try:\n",
    "            img = Image.open(file_path)  # 이미지 열기\n",
    "            img = img.resize(target_size)  # (28, 28)로 리사이즈\n",
    "            img.save(file_path)  # 리사이즈한 이미지 저장\n",
    "            if i % 10 == 0:  # 진행 상태 표시\n",
    "                print(f\"{i}/{total_files} 이미지 리사이즈 완료\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 오류 발생: {file_path} - {e}\")\n",
    "            \n",
    "    print(f\"🎉 모든 이미지 리사이즈 완료 - 총 {total_files}개 파일 리사이즈됨.\")\n",
    "\n",
    "\n",
    "# 🧱 **2. 데이터 로드 함수 (load_data)**\n",
    "def load_data(image_dir_path, target_size=(28, 28)):\n",
    "    print(f\"📥 데이터 로드 중... 경로: {image_dir_path}\")\n",
    "    x_data = []  # 이미지 데이터 (X)\n",
    "    y_data = []  # 라벨 데이터 (Y)\n",
    "    \n",
    "    labels = {'scissor': 0, 'rock': 1, 'paper': 2}  # 가위, 바위, 보 라벨 설정\n",
    "    \n",
    "    for label_name, label_number in labels.items():\n",
    "        label_dir = os.path.join(image_dir_path, label_name)  # 라벨 디렉토리\n",
    "        if not os.path.exists(label_dir):\n",
    "            print(f\"📂 {label_dir} 디렉토리가 존재하지 않습니다. 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        image_files = os.listdir(label_dir)  # 이미지 파일 목록\n",
    "        print(f\"📁 '{label_name}' 라벨의 이미지 개수: {len(image_files)}개\")\n",
    "\n",
    "        for file_name in image_files:\n",
    "            file_path = os.path.join(label_dir, file_name)  # 이미지 파일 경로\n",
    "            try:\n",
    "                img = Image.open(file_path)  # 이미지 열기\n",
    "                img = img.resize(target_size)  # (28, 28)로 리사이즈\n",
    "                img = np.array(img)  # 이미지를 Numpy 배열로 변환\n",
    "                x_data.append(img)  # x_data에 추가\n",
    "                y_data.append(label_number)  # y_data에 라벨 추가\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 오류 발생: {file_path} - {e}\")\n",
    "    \n",
    "    x_data = np.array(x_data)  # 리스트 → Numpy 배열 변환\n",
    "    y_data = np.array(y_data)  # 리스트 → Numpy 배열 변환\n",
    "    print(f\"📏 데이터 로드 완료: x_data.shape={x_data.shape}, y_data.shape={y_data.shape}\")\n",
    "    return x_data, y_data\n",
    "\n",
    "\n",
    "# 📘 **3. 데이터셋 경로 지정**\n",
    "image_dir_path_scissor = os.path.join(os.getenv(\"HOME\"), \"aiffel/rock_scissor_paper/test/scissor\")\n",
    "image_dir_path_rock = os.path.join(os.getenv(\"HOME\"), \"aiffel/rock_scissor_paper/test/rock\")\n",
    "image_dir_path_paper = os.path.join(os.getenv(\"HOME\"), \"aiffel/rock_scissor_paper/test/paper\")\n",
    "\n",
    "# 📁 **4. 이미지 리사이즈 (scissor, rock, paper)**\n",
    "resize_images(image_dir_path_scissor)  # 가위 이미지 리사이즈\n",
    "resize_images(image_dir_path_rock)  # 바위 이미지 리사이즈\n",
    "resize_images(image_dir_path_paper)  # 보 이미지 리사이즈\n",
    "\n",
    "\n",
    "# 📘 **5. x_test, y_test 데이터 생성**\n",
    "image_dir_path = os.path.join(os.getenv(\"HOME\"), \"aiffel/rock_scissor_paper/test\")\n",
    "x_test, y_test = load_data(image_dir_path)  # 이미지 불러오기\n",
    "\n",
    "# 🔍 **6. 데이터 정규화**\n",
    "x_test_norm = x_test / 255.0  # 0~1 사이의 값으로 정규화\n",
    "print(f\"📏 x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e1e4667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 173.4003 - accuracy: 0.3333\n",
      "📉 test_loss: 173.4003\n",
      "📈 test_accuracy: 0.3333\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터로 모델 평가하기\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "\n",
    "# 📢 **평가 결과 출력**\n",
    "print(\"📉 test_loss: {:.4f}\".format(test_loss))\n",
    "print(\"📈 test_accuracy: {:.4f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d668e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
